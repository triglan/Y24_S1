안녕하세요. AI 주제에 대해서 발표하게 된 6조입니다.

[슬라이드 2, 2분]
이 뉴스, 올해 2월에 나왔는데 다들 들어보셨나요?
1750년에 고대 로마의 도시 헤르쿨라네움에서 1천여개의 파피루스 문서가 발굴되었는데요.
이 파피루스 문서들은 79년에 베수비오 화산이라는 화산이 폭발했을 때 화산재에 그을려져,
펼치면 바스러지기 때문에 펼칠 수 없는 상태였어요.
그래서 이 문서들을 여러 각도에서 촬영하고 그 사진들을 바탕으로 문서를 해독하는 대회가 열립니다.
이 대회는 베수비오 챌린지라고 불렸는데요, AI 분야의 일종인 Computer Vision 기술이 이것을 해결할 수 있지 않을까 기대를 건 거죠.
그리고 이 대회를 통해, 올해에 두루마리의 약 5%인 2000글자 정도를 읽어냈습니다.
문서의 내용은 고대 그리스 쾌락주의 철학에 대한 저술이었다고 하는데요,
숯덩이가 되버린 종이의 내용을 복원하는 수준에 이르렀다니 놀랍지 않나요?
Computer Vision은 AI의 주요 분야 중 하나이고요.
이번 발표를 통해 AI의 개요와 분야, 현황과 미래에 대해 소개해드리도록 하겠습니다.

[슬라이드 3, 30초]
인공지능이란 말 그대로 기계가 지능을 갖는다는 것이죠.
우리의 고유 영역이라 느껴지던 창의력, 상상력, 논리력 등등이
기계에도 갖춰진다면, 인간이 해야 하는 일들 상당 부분이 기계로 대체될 수 있겠죠.
여기에 적혀있는 장점들은 기계가 가지는 본연적인 장점이라고도 볼 수 있는데요.
중요한 것은, 여기에 창의력, 상상력, 논리력이 더해진다는 것입니다.

[슬라이드 4, 35초]
인공지능의 종류는 기준을 어떻게 나누느냐에 따라 여러가지 구분이 있겠지만,
지능의 수준을 따졌을 때
ANI, AGI, ASI로 나눠볼 수 있습니다.
"ANI"는 특정 분야에 한정하여 지능적인 동작을 "모방"할 수 있는 AI,
"AGI"는 인간처럼 모든 분야에서 지능적인 동작을 "수행"할 수 있는 AI이고,
"ASI"는 저희가 느끼기엔 다소 SF적인 개념으로, 인간의 이해를 넘어서 사고하고 행동하는 AI를 말합니다.

[슬라이드 5, 15초]
약인공지능은 ANI와 유사하게 쓰이는 용어입니다.
가볍게 한 번 읽어봐 주세요.

[슬라이드 6, 20초]
강인공지능은 아직 도달되지 않은, 이론적 형태의 AI로,
종전의 AGI, ASI와 유사하게 쓰이는 용어입니다.
마찬가지로 가볍게 한 번 읽어봐 주세요.

[슬라이드 7, 2분]
1950년에 앨런 튜링은 기계가 얼마나 인간과 비슷하게 대화할 수 있는지를 판별하는, "튜링 테스트"를 제안했습니다.
여러분이 모르는 여러 명의 상대와 대화를 하는데, 그 대화 상대는 컴퓨터일 수도 있고 실제 사람일 수도 있습니다.
여러분이 대화를 마치고 상대가 컴퓨터인지 사람인지 판정을 하는데,
컴퓨터의 사람 판정률이 30% 이상이 된다면, 그 컴퓨터를 지능을 가진 것으로 간주한다는 것이죠.

1967년에 생물의 뉴런을 모방한 수학적 개념인 퍼셉트론이 등장합니다.
뉴런을 모방했다고 그렇게 거창한 것이 아니라, 여러분들도 전부 이해할 수 있습니다.
어떤 벡터 입력에 대해 특정한 벡터를 출력하려고 합니다.
입력 벡터를 출력 벡터로 조작하는 데엔 뭐가 필요할까요? 행렬곱이 필요하겠죠?
지금은 이정도만 하고, 뒤에 가서 더 자세히 소개하겠습니다.
이 퍼셉트론이 발전되어 "신경망"이라고 불리게 되어요.

그리고 1970~80년 즈음에 현대 신경망에서 쓰이는 오류 역전파 알고리즘이 등장하는데요
아까 입력 벡터를 출력 벡터로 조작하는 데엔 행렬곱이 필요하다고 했죠?
오류의 역전파라는 것은, 그렇게 행렬 곱을해서 나온 출력 벡터가
우리가 알고있는 정답과 달랐을 때, 그 "오류"를 줄이는 방향으로 행렬의 원소들을 갱신하는 겁니다.
미분이 활용되고, 확률적인 요소도 첨가돼요.

나머지는 1997년, 2011년, 2012년, 2016년에 AI가 거둔 성과들을 짚어볼 만 하겠습니다.
넘어가겠습니다.

[슬라이드 8, 25초]
인공지능 기술은 세간의 주목을 물씬 받았다가 기대에 못미쳐 암흑기를 겪는 과정들이
마치 파도처럼 요동치듯이 여러 번 있어왔는데요.

간단하게 눈에만 익히시면 괜찮을 듯 합니다.
초창기엔, 퍼셉트론이 비선형 분류 문제를 해결하지 못한다는 사실이 증명되어
암흑기가 시작되었어요.

[슬라이드 9, 8초]
그래서 사람들은 퍼셉트론에서 눈을 돌려 통계 기술들에 집중하기 시작했죠.

[슬라이드 10, 8초]
그러나 모든 산업에서 모든 순간에 도움이 됐던 것은 아니었습니다.

[슬라이드 11, 35초]
그 사이에 퍼셉트론을 근간으로 한 신경망 기술은
여러 최적화 기법들이 발견되고, 하드웨어 성능이 좋아지면서
가중치 보존과 막대한 연산량으로 기존의 약점을 커버하기 시작합니다.
곱하는 행렬의 수가 많아진 거에요.
그 행렬 하나 하나를 층이라고 부르는데,
층이 많으면 깊다고 해서 '딥러닝'이라고 부릅니다.
기준은 정해진 것이 없어서, 보통 입력층과 출력층 사이 "은닉층"이 3개 이상일 때 깊다고 합니다.

[슬라이드 12, 10초]
그렇게 AI는 오늘날 우리가 마주하게 되는 어떠한 특이점에 도달한 기술로 발전하죠.

[슬라이드 13, 35초]
기계를 학습시킨다는 것의 의미는 뭘까요?
여러분이 세세한 지시 없이 무언갈 요청했을때,
기계가 척척 알아서 동작을 수행한다면
기계가 학습을 한다고 말할 수 있습니다.
좀 세련되게 말하면,
여러분이 원하는 동작을 직접 프로그래밍하지 않고도
기계가 적절히 수행하도록 한다는 것이죠.
이것을 "기계학습"이라고 부릅니다.

그리고 기계학습에는 세 가지의 종류가 있어요.
지도학습, 비지도학습, 강화학습인데요.

[슬라이드 14, 15초]
지도학습은 사전 준비된 학습 데이터에 정답이 포함된 경우입니다.
기계를 학습시키려면 학습 자료가 있어야겠죠?
그 학습 자료에 답지까지 있는 것을 지도학습이라고 합니다.

[슬라이드 15, 35초]
이미지 분류는 여러분들이 많이 보셨을 테니, 회귀를 소개해드릴게요.
사실 회귀는 분류보다 더 쉬운 문제입니다.
어떠한 실험을 할 때, 상관이 있는 변수들은 함수 관계를 가지고,
그것을 그래프로 그릴 수가 있죠?
회귀는 그 함수 관계를 찾는 것이고, 그래프의 추세선을 찾는 것입니다.
특정 변수가 어떤 게 주어졌을 때, 그에 대응되는 다른 변수는 어떤 값을 가지겠느냐
추론하는 알고리즘이에요.

[슬라이드 16, 15초]
비지도 학습은 답지가 없는 학습입니다.
답지가 없어도 코사인 유사도나 유클리드 거리 같은 수학적 특성으로
데이터의 패턴을 찾아낼 수 있죠.

[슬라이드 17, 35초]
예시는 클러스터링입니다.
여러분들이 마트에 들어가서 이동하는 동선을 수집해서,
어떤 동선을 따르는 고객이 어떤 상품을 구매할 확률이 높은지
특정한 기준을 가지고 분류를 합니다.
그 분류가 일반적이고 정확할수록 더 효율적인 상품 배치를 할 수 있겠죠.

[슬라이드 18, 20초]
강화 학습은 정답이 없는 문제를 해결하는데 초점화되어있습니다.
대신, 가능한 한 최대 보상을 얻을 수 있도록 학습하죠.
현재 상황이 어떤지, 어떤 행동을 할 것인지, 행동의 순서는 어떻게 할 것인지를 결정하도록 합니다.

[슬라이드 19, 55초]
예시는 자율 주행입니다.
운전에는 변수가 너무 많죠?
대표적인 정답이 없는 문제 중 하나입니다.
재미있는 점은, 운전에 대한 판단을 내리는 것도 AI의 한 분야고,
그 판단을 위한 정보를 수집하는 것도 AI의 한 분야라는 것입니다.

강화학습이 담당하는 것은 운전에 대한 판단을 내리는 것이고요.
판단을 위한 정보를 수집하는 것은 Computer Vision의 역할입니다.

사족으로,
자율주행에서 Computer Vision은 센서 기술과 경쟁하는데요.
센서들은 비쌉니다.
비싼 센서를 쓰는 대신에, 카메라로 사진을 찍고
소프트웨어적으로 도로 상황을 인식하면
비용을 획기적으로 줄일 수 있습니다.
그래서 Computer Vision의 예시들은 대부분
사람과 도로, 나무와 차를 인식하는 것들이 많아요.

[슬라이드 20, 35초]
강화학습에는 예시가 하나 더 있습니다.
알파고죠.
바둑을 위시한 게임들도 마찬가지로 정답 찾기보단,
점수를 높이기 혹은 이길 확률 높이기 등으로 해결하기 적합합니다.
AlphaGo는 그중에서 Go, Go가 한국어로 바둑이거든요?
바둑에 쓰였던 모델이고,
점점 게임 분야를 넓혀서 다양한 보드게임과 심지어는 스타크래프트 같은 어려운 게임도
성공적으로 학습을 완수했습니다.

[슬라이드 21, 25초]
게임들을 학습하면서 얻어낸 강화학습 노하우들은 이제,
강화학습을 적용할 수 있는 다른 분야에 활용되기 시작합니다.
게임을 통해 화제성을 모아 투자를 받고,
그 연구를 바탕으로 실용적인 모델로 옮겨가는 거죠.
화학, 양자역학, 의학, 생명공학 뭐 사실상 적용이 안 될 분야가 잘 없습니다.
지켜보는 것이 좋겠죠.

[슬라이드 22, 2분]
앞에서 기계학습과 그 종류인 지도학습, 비지도학습, 강화학습에 대해서 알아봤는데요.
기계를 학습시킨다는 개념은 이해를 했습니다.
그러면 어떻게 기계를 학습시킬까요?
누가 뭐래도 현재 기계학습 알고리즘의 주축은 다 신경망 기반입니다.

아까 퍼셉트론에 대해서 간략히 설명을 했죠.
입력 벡터와 출력 벡터가 있고,
출력 벡터를 이끌어내기 위해 행렬곱들이 동원됩니다.
우리는 이걸 3D 그래픽하면서 이미 하고 있기 때문에 당연하게도 쉽게 이해할 수 있습니다.
변환이죠?
변환을 거쳐서 출력 벡터를 만드는데,
신경망 이론에선 입력 벡터를 "입력 층",
행렬곱을 통해 출력 벡터가 나오는 구조를 "출력 층",
그리고 입력 층과 출력 층 사이에 추가적인 행렬곱과 중간 벡터가 있다면 그것을 "은닉 층"이라고 부릅니다.

변환을 한 번 하면 입력 층과 출력 층만 있는 거고,
두 번 이상하면 은닉 층이 존재하게 되는 거에요.

그림에 화살표들의 양상을 보시면, 행렬곱이겠구나라는 게 추론이 되실 거에요.
왜 하드웨어의 발전이 신경망 부활의 핵심 이유였는지도 눈치챌 수 있죠?
1024x768 불투명 이미지는 RGB채널까지 포함해서 1024x768x3의 크기를 가지는 벡터입니다.
중간 벡터의 크기가 n이라면 가중치 행렬의 행은 1024x768x3 크기고, 열은 n 크기인 거에요. (열 벡터 기준)
그리고 그 행렬을 벡터와 곱한다니 연산량이 말도 안 되게 많은 겁니다.

[슬라이드 23, 1분 5초]
최적화 기법들과 하드웨어의 발전으로 행렬곱을 더 많이 수용할 수 있게 되면서,
은닉층을 여러 개 둘 수 있게 되었습니다.
그렇게 기존보다 은닉층이 많은 신경망을 별도로 DNN, Deep Neural Network라고 불렀는데요.
명확한 기준은 존재하지 않습니다. 애초에 요즘은 은닉층이 겨우 1~2개인 신경망은 
해석 가능성 이슈 해결이나 프로토타이핑을 위한 게 아니라면 잘 쓰지도 않습니다.

그리고 우리는 이 알고리즘이 돌아가는 과정을 가만히 보다보니
앞쪽의 행렬에서 더 추상적이고 상위의 특징들이,
뒤쪽의 행렬에서 더 구체적이고 하위의 특징들이 분류된다는 것을 알게 돼요.

이제 신경망의 발전은,
층을 얼마나 효과적으로 깊게 할 수 있느냐가 관건이 되었습니다.
그렇게, CNN, RNN, LSTM, GRU 같은 기술들이 태동되었어요.

[슬라이드 24, 1분]
CNN은 인간의 시각 뉴런이 "부분 연결" 구조를 띈다는 점에 착안한 기술입니다.
행렬곱은 벡터 내적의 연속인 만큼, 구성된 벡터의 길이가 길면 그만큼 연산량이 늘어나잖아요?
그런데 실제 데이터의 특징들은, 벡터의 특정 부분에 몰려있는 경향이 있습니다. "지역성"이 있는 거죠.
그래서 CNN은, 인접한 원소들을 모아 작은 행렬로 구성한 후,
그 행렬에 합성곱이라는 연산을 하는 것으로 가중치를 반영합니다.
합성곱 연산은 전체 벡터의 길이를 알 필요가 없기 때문에 가변 길이 입력에도 대응이 가능합니다.
일반적으로 CNN은 Computer Vision에서 많이 활용되고,
CNN의 한 종류인 1d-CNN은 시계열 데이터 분석에 많이 활용됩니다.

[슬라이드 25, 25초]
Computer Vision 사례를 하나 보여드리겠습니다.
Apache의 MXNet 발표 자료인데요,
아까 말씀드린 것처럼
도로, 나무, 사람, 차를 구분하고 있죠.
건물도 구분하고 있는 것 같습니다.
각각 색깔이 마스킹이 되어있네요.

[슬라이드 26, 50초]
RNN은 한 층의 출력이 다른 층의 입력이 될 수 있다 하여
순환 신경망이라고 하는데요.

순차 데이터를 처리하는데 쓰입니다.
순차 데이터에는 시간성, 가변 길이, 문맥 의존성 등의 특징이 있는데요.

대표적인 예시는 자연어 문장입니다.
단어의 순서를 바꾸면 의미가 달라지죠?
이 문장에서 그녀와 철수를 바꾸면 의미가 달라집니다.
자연어 문장이 가변 길이인 건 당연하고,
"그녀는"과 "아점을", 그리고 "먹었는데" 이 세 단어는
하나의 작은 문장을 이룰 수 있는데요.
"그녀는"과 "아점을"은 원래 문장에서 굉장히 멀리 떨어져 있습니다.
그럼에도 불구하고 상호 의존적이죠.
문맥이 있다는 것입니다.

[슬라이드 27, 25초]
RNN이 활용되는 분야 중 하나는 OCR(광학 문자 인식)인데요.
LSTM은 RNN에서 오래된 정보를 잊을 수 있는 망각 게이트가 추가되고 각종 최적화 기법이 적용된 기술입니다.
Tesseract는 바로 그 LSTM이 적용된 오픈소스 프로젝트에요.
손글씨에는 획이 있기 때문에, 단순히 이미지로만 보지는 않습니다.
컴퓨터 글씨만을 읽을 것이라면 Computer Vision이 더 일을 잘 처리하겠지만,
여러분의 손글씨는 RNN 계열이 활약하는 분야죠.

[슬라이드 28, 15초]
현재 가장 핫한 분야이자, 미래가 기대되는 분야는 생성형 AI입니다.
분류 모델의 출력과 입력이 거꾸로 된다는 것은 이따가 설명하겠고요.
그림을 그리는 Dall-E, 채팅을 하는 ChatGPT, 뭐 유튜브에 많이 보이는 AI 커버 노래 등
전부 이 분야의 산물입니다.

[슬라이드 29, 25초]
둘 중 하나는, AI로 저희가 직접 생성한 일론 머스크의 이미지입니다.
누가 진짜 일론 머스크일까요?

네, 모델 최적화와 후처리를 안 했기 때문에 티가 좀 나는데,
위쪽이 진짜 일론 머스크입니다.

이렇게 "진짜 같은 가짜"를 만드는 것이 어떻게 가능할까요?

[슬라이드 30, 1분]
우리가 기존에 학습시킨 AI들은 대부분 분류 모델인데요.
잘 학습된 분류 모델이 있으니까, 이런 일을 할 수 있는 겁니다.
내가 랜덤하게 만든 이미지와 기존 이미지들을 섞어서 분류 모델한테 분류를 시켜요.
이것은 내가 만든 이미지일까? 아닐까? 하고요.
분류 모델이 정답을 잘 맞춘다면, 이 이미지는 가짜 티가 많이 나는 이미지라는 거겠죠.
오류 역전파를 통해서 점점 분류 모델이 정답을 못 맞추도록 만든다면,
그리고 결과적으로 분류 모델의 정답률이 50%라면,
분류 모델은 진짜와 가짜를 분류하지 못한다고 말할 수 있습니다.

분류 모델과 생성 모델이 경쟁한다 그래서 이것은
경쟁적 생성 신경망, GAN이라고 불러요.

[슬라이드 31, 15초]
ChatGPT, 이미 많이 활용하고 계시죠?
얼마 전에 또 새로운 모델이 나왔던데,
pdf 하나를 통째로 이해해 문맥을 유지하는 모습도 보여주더라고요.
정말 무시무시합니다.

[슬라이드 32, 30초]
여러분들한테 Github Copilot을 굉장히 추천드리고 싶은데요.
그림에 보이는 회색 부분이 코파일럿이 코드를 제안해주는 부분입니다.
여러분이 가만히 있으면 코파일럿이 코드를 제안해주고,
여러분은 그냥 Tab 키를 눌러서 해당 제안을 수락하기만 하면 돼요.

Copilot이 알고리즘을 짜는 것이나 아이디어를 만드는 데에는 아직까지 그렇게 효과적이지는 않은데요.
여러분이 작성하려는 코드의 5%만 타이핑해도 Copilot은 어떤 코드를 작성할지 다 눈치채기 때문에
타이핑을 줄이는데 굉장히 효과적으로 활용할 수 있습니다.

[슬라이드 33, 25초]
CivitAI는 이미지 생성 AI 서비스를 웹을 통해 제공받을 수 있는 서비스인데요.
슬라이드의 내용은 이런 게 있다 정도로만 보시면 될 것 같습니다.

AI를 이용한 웹 서비스들이 많긴 하지만,
CivitAI는 이미 널리 쓰여 일종의 플랫폼화가 되어서요.
기회가 된다면 한 번쯤 접해보시는 것도 나쁘지 않겠습니다.

[슬라이드 34, 30초]
CivitAI를 통해 이미지를 생성하는 예시입니다.
적용할 모델들을 선택하고, 프롬프트를 주면 이렇게 이미지를 만들어줘요.

프롬프트가 예시에서는 자연어 문장으로 되어있는데,
기본적으로 GAN은 분류모델을 혼란시키도록 훈련되기 때문에
자연어 문장보다는 단어 위주의 입력에 강합니다.

[슬라이드 35, 10초]
3D Asset을 만들어주는 MasterpieceX라는 서비스도 있습니다.

Dragon Sword, Strong, Sharp, Heavy라는 프롬프트를 주었는데요.

[슬라이드 36, 10초]
이렇게 뚝딱 3D Asset을 만들어 주었습니다.

[슬라이드 37, 1분]
생성 모델이 앞으로 더욱 발전할 부분은, "통제 가능성"입니다.

현재 Dall-E등의 모델로 AI 이미지 생성을 해보신 분들은 알겠지만,
내가 머리속에 떠올린 이미지를 프롬프트로 묘사하기도 어렵고,
결과는 너무나도 랜덤하게 나옵니다.
일종의 과소적합인데요.

딥러닝에서 몇 개의 은닉층을 사전 훈련된 별도의 층으로 대체하거나,
중간에 특정 층을 삽입하는 것으로 통제 능력을 얻을 수 있다는 것이 증명되어왔습니다.

이것은 ControlNet이라는 기술의 논문에서 발췌한 그림인데요.
다양한 소스를 통제 요소로 삼아 이미지를 생성해낼 수 있습니다.

만약 Asset이나 코딩 작업에 있어서 생성형 AI를 활용하고 싶다 하시면,
해당 기술이 발전하면서 통제 가능성이 더더욱 열리기를 바라셔야겠습니다.